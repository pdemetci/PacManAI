
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: module pacmanAgents</title>
<meta charset="utf-8">
</head><body bgcolor="#f0f0f8">

<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="#7799ee">
<td valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial">&nbsp;<br><big><big><strong>pacmanAgents</strong></big></big></font></td
><td align=right valign=bottom
><font color="#ffffff" face="helvetica, arial"><a href=".">index</a><br><a href="file:/home/snorthway/semester-8/softdes/PacMan-AI/PacMan1/pacmanAgents.py">/home/snorthway/semester-8/softdes/PacMan-AI/PacMan1/pacmanAgents.py</a></font></td></tr></table>
    <p><tt>Glue&nbsp;for&nbsp;interfacing&nbsp;with&nbsp;the&nbsp;Berkeley&nbsp;code.<br>
@author&nbsp;Stephanie&nbsp;Northway,&nbsp;Kelly&nbsp;Brennan&nbsp;and&nbsp;Pinar&nbsp;Demetci</tt></p>
<p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#aa55cc">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Modules</strong></big></font></td></tr>
    
<tr><td bgcolor="#aa55cc"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><table width="100%" summary="list"><tr><td width="25%" valign=top><a href="operator.html">operator</a><br>
</td><td width="25%" valign=top><a href="pickle.html">pickle</a><br>
</td><td width="25%" valign=top><a href="random.html">random</a><br>
</td><td width="25%" valign=top></td></tr></table></td></tr></table><p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ee77aa">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#ffffff" face="helvetica, arial"><big><strong>Classes</strong></big></font></td></tr>
    
<tr><td bgcolor="#ee77aa"><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</tt></td><td>&nbsp;</td>
<td width="100%"><dl>
<dt><font face="helvetica, arial"><a href="game.html#Agent">game.Agent</a>(<a href="__builtin__.html#object">__builtin__.object</a>)
</font></dt><dd>
<dl>
<dt><font face="helvetica, arial"><a href="pacmanAgents.html#SimpleQPacman">SimpleQPacman</a>
</font></dt></dl>
</dd>
</dl>
 <p>
<table width="100%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="#ffc8d8">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="#000000" face="helvetica, arial"><a name="SimpleQPacman">class <strong>SimpleQPacman</strong></a>(<a href="game.html#Agent">game.Agent</a>)</font></td></tr>
    
<tr bgcolor="#ffc8d8"><td rowspan=2><tt>&nbsp;&nbsp;&nbsp;</tt></td>
<td colspan=2><tt>Represents&nbsp;the&nbsp;pacman&nbsp;agent&nbsp;that&nbsp;implements&nbsp;the&nbsp;continuous&nbsp;state&nbsp;Q-learning<br>
algorithm&nbsp;to&nbsp;learn&nbsp;from&nbsp;it's&nbsp;previous&nbsp;exerience.&nbsp;The&nbsp;agent&nbsp;inherits&nbsp;the<br>
attritbutes&nbsp;and&nbsp;methods&nbsp;from&nbsp;the&nbsp;Berkeley&nbsp;<a href="game.html#Agent">Agent</a>&nbsp;Class.<br>
&nbsp;<br>
features:&nbsp;a&nbsp;list&nbsp;of&nbsp;Features&nbsp;the&nbsp;agent&nbsp;will&nbsp;use<br>
tiles:&nbsp;dictionary&nbsp;to&nbsp;hold&nbsp;all&nbsp;of&nbsp;the&nbsp;tiles&nbsp;on&nbsp;the&nbsp;game&nbsp;layout<br>
learningRate:&nbsp;how&nbsp;much&nbsp;you&nbsp;adjust&nbsp;the&nbsp;weight&nbsp;relative&nbsp;to&nbsp;the&nbsp;Q-value<br>
discountFactor:&nbsp;Weight&nbsp;to&nbsp;balance&nbsp;instant&nbsp;reward&nbsp;with&nbsp;future&nbsp;long&nbsp;term&nbsp;awards<br>
exploraitonRate:&nbsp;probability&nbsp;that&nbsp;pacman&nbsp;will&nbsp;explore,&nbsp;instead&nbsp;of&nbsp;using&nbsp;optimal&nbsp;action<br>&nbsp;</tt></td></tr>
<tr><td>&nbsp;</td>
<td width="100%"><dl><dt>Method resolution order:</dt>
<dd><a href="pacmanAgents.html#SimpleQPacman">SimpleQPacman</a></dd>
<dd><a href="game.html#Agent">game.Agent</a></dd>
<dd><a href="__builtin__.html#object">__builtin__.object</a></dd>
</dl>
<hr>
Methods defined here:<br>
<dl><dt><a name="SimpleQPacman-__init__"><strong>__init__</strong></a>(self, fromPickle<font color="#909090">=True</font>)</dt><dd><tt>Pickling&nbsp;the&nbsp;feature&nbsp;weights&nbsp;for&nbsp;agent&nbsp;to&nbsp;learn&nbsp;from&nbsp;its&nbsp;actions&nbsp;in&nbsp;previous&nbsp;GameState</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getAction"><strong>getAction</strong></a>(self, state)</dt><dd><tt>getAction&nbsp;runs&nbsp;pacman&nbsp;agent's&nbsp;show&nbsp;by&nbsp;determing&nbsp;what&nbsp;action&nbsp;the<br>
agent&nbsp;will&nbsp;take,&nbsp;based&nbsp;on&nbsp;it's&nbsp;current&nbsp;state&nbsp;and&nbsp;Q-learning&nbsp;values<br>
&nbsp;<br>
Initialize&nbsp;the&nbsp;game&nbsp;layout&nbsp;tiles&nbsp;when&nbsp;pacman&nbsp;is&nbsp;in&nbsp;start&nbsp;configuration<br>
Updates&nbsp;the&nbsp;pacman's&nbsp;feature&nbsp;values<br>
Determines&nbsp;the&nbsp;agent's&nbsp;optimal&nbsp;action,&nbsp;given&nbsp;its&nbsp;specific&nbsp;configuration<br>
based&nbsp;on&nbsp;the&nbsp;maximum&nbsp;Q&nbsp;value&nbsp;or&nbsp;implements&nbsp;a&nbsp;random&nbsp;action<br>
Updates&nbsp;feature&nbsp;weights&nbsp;based&nbsp;on&nbsp;it's&nbsp;final&nbsp;action<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
returns:&nbsp;random&nbsp;action,&nbsp;if&nbsp;exploring,&nbsp;and&nbsp;optimal&nbsp;action,&nbsp;if&nbsp;not&nbsp;exploring</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getApproximateQValue"><strong>getApproximateQValue</strong></a>(self, state)</dt><dd><tt>Calculate&nbsp;the&nbsp;linear&nbsp;combination&nbsp;of&nbsp;the&nbsp;feature&nbsp;values&nbsp;and&nbsp;their<br>
respective&nbsp;weights&nbsp;to&nbsp;approximate&nbsp;Q-value.<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
return:&nbsp;Approximate&nbsp;Q&nbsp;value&nbsp;based&nbsp;on&nbsp;the&nbsp;feature&nbsp;weights,&nbsp;#</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getExpectedNextReward"><strong>getExpectedNextReward</strong></a>(self, state, action)</dt><dd><tt>More&nbsp;reward&nbsp;is&nbsp;given&nbsp;when&nbsp;pacman&nbsp;agent&nbsp;increases&nbsp;the&nbsp;score&nbsp;with&nbsp;it's&nbsp;action<br>
Calculate&nbsp;the&nbsp;expected&nbsp;reward&nbsp;of&nbsp;a&nbsp;given&nbsp;state&nbsp;and&nbsp;action&nbsp;based&nbsp;on&nbsp;score&nbsp;change<br>
r_t+1&nbsp;=&nbsp;R(s_t,&nbsp;a_t,&nbsp;s_t+1)<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
Action:&nbsp;direction&nbsp;(string)<br>
return:&nbsp;change&nbsp;in&nbsp;score&nbsp;based&nbsp;on&nbsp;action</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getMaxQ"><strong>getMaxQ</strong></a>(self, state)</dt><dd><tt>Calculate&nbsp;the&nbsp;Q-values&nbsp;of&nbsp;all&nbsp;the&nbsp;legal&nbsp;actions&nbsp;and&nbsp;determine&nbsp;max&nbsp;Q-value<br>
to&nbsp;determine&nbsp;the&nbsp;optimal&nbsp;action<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
return:&nbsp;action,&nbsp;maximum&nbsp;Q-value&nbsp;(tuple:&nbsp;string,&nbsp;float)</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getMaxQAction"><strong>getMaxQAction</strong></a>(self, state)</dt><dd><tt>return&nbsp;action&nbsp;with&nbsp;max&nbsp;Q-value&nbsp;of&nbsp;given&nbsp;agent&nbsp;state<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
return:&nbsp;action&nbsp;with&nbsp;the&nbsp;maximum&nbsp;Q-value&nbsp;(string)</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getMaxQValue"><strong>getMaxQValue</strong></a>(self, state)</dt><dd><tt>return&nbsp;max&nbsp;Q-value&nbsp;of&nbsp;given&nbsp;agent&nbsp;state<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
return:&nbsp;maximum&nbsp;Q-Value&nbsp;(float)</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-getQValue"><strong>getQValue</strong></a>(self, state, action)</dt><dd><tt>Calculate&nbsp;the&nbsp;Q-Value&nbsp;based&nbsp;on&nbsp;algorithm<br>
Q'&nbsp;=&nbsp;(1-learningRate)&nbsp;*&nbsp;(Q&nbsp;+&nbsp;learningRate)&nbsp;*&nbsp;(R&nbsp;+&nbsp;R')<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
action:&nbsp;direction&nbsp;(string)<br>
return:&nbsp;Q-value&nbsp;(float)</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-isExploring"><strong>isExploring</strong></a>(self)</dt><dd><tt>Uses&nbsp;explorationRate&nbsp;to&nbsp;decide&nbsp;if&nbsp;pacman&nbsp;agent&nbsp;explores&nbsp;or&nbsp;uses&nbsp;Q-learning<br>
&nbsp;<br>
returns:&nbsp;True&nbsp;or&nbsp;False</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-lose"><strong>lose</strong></a>(self, state)</dt><dd><tt>Stores&nbsp;feature&nbsp;weight&nbsp;values&nbsp;when&nbsp;game&nbsp;ends&nbsp;so&nbsp;pacman&nbsp;agent&nbsp;can&nbsp;learn&nbsp;from&nbsp;experience<br>
over&nbsp;multiple&nbsp;games<br>
Update&nbsp;the&nbsp;feature&nbsp;weights&nbsp;and&nbsp;store&nbsp;by&nbsp;pickling&nbsp;when&nbsp;pacman&nbsp;agent&nbsp;loses<br>
&nbsp;<br>
input:&nbsp;GameState&nbsp;object<br>
output:&nbsp;feature&nbsp;weights&nbsp;in&nbsp;pickle&nbsp;file</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-updateFeatures"><strong>updateFeatures</strong></a>(self, state)</dt><dd><tt>Update&nbsp;the&nbsp;feature&nbsp;values<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object<br>
returns:&nbsp;None</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-updateWeights"><strong>updateWeights</strong></a>(self, state, action)</dt><dd><tt>Essential&nbsp;for&nbsp;pacman&nbsp;learning&nbsp;what&nbsp;features&nbsp;are&nbsp;most&nbsp;important&nbsp;for&nbsp;earning&nbsp;rewards<br>
negative&nbsp;weight&nbsp;values&nbsp;-&nbsp;pacman&nbsp;attracted&nbsp;toward&nbsp;feature&nbsp;to&nbsp;increase&nbsp;reward<br>
&nbsp;&nbsp;&nbsp;&nbsp;ex.&nbsp;agent&nbsp;going&nbsp;towards&nbsp;food<br>
positive&nbsp;weight&nbsp;values&nbsp;-&nbsp;pacman&nbsp;repelled&nbsp;by&nbsp;feature&nbsp;to&nbsp;increase&nbsp;reward<br>
&nbsp;&nbsp;&nbsp;&nbsp;ex.&nbsp;agent&nbsp;going&nbsp;away&nbsp;from&nbsp;ghosts<br>
&nbsp;<br>
update&nbsp;weight&nbsp;values&nbsp;of&nbsp;each&nbsp;feature&nbsp;based&nbsp;on&nbsp;the&nbsp;change&nbsp;in&nbsp;that<br>
feature&nbsp;from&nbsp;the&nbsp;last&nbsp;state.<br>
w_t+1&nbsp;=&nbsp;w_t&nbsp;+&nbsp;alpha(r_t+1&nbsp;+&nbsp;gamma*&nbsp;max(a)Q(s',&nbsp;a)&nbsp;-&nbsp;Q(s,&nbsp;a))*phi_t<br>
&nbsp;<br>
state:&nbsp;GameState&nbsp;object,<br>
action:&nbsp;direction&nbsp;(string)<br>
return:&nbsp;None</tt></dd></dl>

<dl><dt><a name="SimpleQPacman-win"><strong>win</strong></a>(self, state)</dt><dd><tt>Stores&nbsp;feature&nbsp;weight&nbsp;values&nbsp;when&nbsp;game&nbsp;ends&nbsp;so&nbsp;pacman&nbsp;agent&nbsp;can&nbsp;learn&nbsp;from&nbsp;experience<br>
over&nbsp;multiple&nbsp;games<br>
Update&nbsp;the&nbsp;feature&nbsp;weights&nbsp;and&nbsp;store&nbsp;by&nbsp;pickling&nbsp;when&nbsp;pacman&nbsp;agent&nbsp;wins<br>
&nbsp;<br>
input:&nbsp;GameState&nbsp;object<br>
output:&nbsp;feature&nbsp;weights&nbsp;in&nbsp;pickle&nbsp;file</tt></dd></dl>

<hr>
Data descriptors inherited from <a href="game.html#Agent">game.Agent</a>:<br>
<dl><dt><strong>__dict__</strong></dt>
<dd><tt>dictionary&nbsp;for&nbsp;instance&nbsp;variables&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
<dl><dt><strong>__weakref__</strong></dt>
<dd><tt>list&nbsp;of&nbsp;weak&nbsp;references&nbsp;to&nbsp;the&nbsp;object&nbsp;(if&nbsp;defined)</tt></dd>
</dl>
</td></tr></table></td></tr></table>
</body></html>