---
layout: post
title:  "References"
date:   2015-05-05 00:00:00
categories: jekyll update
---

**References**

We couldn't have done this project without loads of help from these great resources:

- [UC Berkeley CS188 Intro to AI course materials](http://ai.berkeley.edu/project_overview.html), including the Pacman game code
- Paul Ruvolo
- Mnemosyne Studio, [A Painless Q-Learning Tutorial](http://mnemstudio.org/path-finding-q-learning-tutorial.htm). 
- Hado van Hasselt, [Reinforcement Learning in Continuous State and Action Spaces](http://webdocs.cs.ualberta.ca/~vanhasse/papers/RL_in_Continuous_Spaces.pdf)
- Chris Gaskett, David Wettergreen, and Alexander Zelinsky, [Q-Learning in Continuous State and Action Spaces](http://users.cecs.anu.edu.au/~rsl/rsl_papers/99ai.kambara.pdf)
- Richard Sutton and Andrew Barto, [Reinforcement Learning: an Introduction](http://webdocs.cs.ualberta.ca/~sutton/book/ebook/the-book.html)
- Rajiv Eranki, [Pathfinding with A* (A-star)](http://web.mit.edu/eranki/www/tutorials/search/), 2002 
- Ray Wenderlich, [Introduction to A* Pathfinding](http://www.raywenderlich.com/4946/introduction-to-a-pathfinding), 2011
- SoftDes toolboxes: “Algorithms and AI”
- SoftDes NINJAs, especially Dennis Chen and Ian Hill
- Wikipedia
